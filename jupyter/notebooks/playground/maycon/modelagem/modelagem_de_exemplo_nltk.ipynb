{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mayco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from unidecode import unidecode\n",
    "## ler arquivo json em pandas\n",
    "df = pd.read_json('C:\\\\Users\\\\mayco\\\\Documents\\\\projetos\\\\data-pantanaldev\\\\label-studio\\\\data\\\\export\\\\project-1-at-2023-04-27-03-26-58dd1708.json')\n",
    "df = df.drop(['id'], axis=1)\n",
    "## expandir coluna annotations\n",
    "df = pd.concat([df.drop(['annotations'], axis=1), df['annotations'].apply(pd.Series)], axis=1)\n",
    "## expandir coluna 0 e renomear para annotations\n",
    "df = pd.concat([df.drop([0], axis=1), df[0].apply(pd.Series)], axis=1)\n",
    "## expandir coluna result e renomear para result\n",
    "df = pd.concat([df.drop(['result'], axis=1), df['result'].apply(pd.Series)], axis=1)\n",
    "df = df.drop(['id'], axis=1)\n",
    "\n",
    "## expandir coluna 0 e renomear para result\n",
    "df = pd.concat([df.drop([0], axis=1), df[0].apply(pd.Series)], axis=1)\n",
    "## expandir coluna value e renomear para value\n",
    "df = pd.concat([df.drop(['value'], axis=1), df['value'].apply(pd.Series)], axis=1)\n",
    "## dropar choices nulos\n",
    "df = df.dropna(subset=['choices'])\n",
    "## obter choices \n",
    "df['choices'] = df['choices'].apply(lambda x: x[0])\n",
    "\n",
    "## expandir coluna data\n",
    "df = pd.concat([df.drop(['data'], axis=1), df['data'].apply(pd.Series)], axis=1)\n",
    "\n",
    "df_noticia_original = df.copy()\n",
    "\n",
    "\n",
    "padrao_data_cepea = r\"Cepea, \\d{2}/\\d{2}/\\d{4} - \"\n",
    "df['noticia'] = df['noticia'].apply(lambda x: re.sub(padrao_data_cepea, '', x))\n",
    "\n",
    "## remover a palavra 'cepea' das noticias\n",
    "padrao_cepea = r\"Cepea\"\n",
    "df['noticia'] = df['noticia'].apply(lambda x: re.sub(padrao_cepea, '', x, flags=re.IGNORECASE))\n",
    "\n",
    "## remover numeros das noticias\n",
    "padrao_numeros = r'[0-9]+'\n",
    "df['noticia'] = df['noticia'].apply(lambda x: re.sub(padrao_numeros, '', x))\n",
    "\n",
    "## noticia que contem a palavra 'soja'\n",
    "df = df[df['noticia'].str.contains('soja', flags=re.IGNORECASE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "MultinomialNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negativa       0.64      0.88      0.74         8\n",
      "      Neutra       1.00      0.10      0.18        10\n",
      "    Positiva       0.67      0.89      0.76        18\n",
      "\n",
      "    accuracy                           0.67        36\n",
      "   macro avg       0.77      0.62      0.56        36\n",
      "weighted avg       0.75      0.67      0.60        36\n",
      "\n",
      "[[ 7  0  1]\n",
      " [ 2  1  7]\n",
      " [ 2  0 16]]\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Selecionar apenas as colunas necessárias\n",
    "columns_to_select = ['id', 'data', 'noticia', 'titulo', 'choices', 'unique_id']\n",
    "df = df[columns_to_select]\n",
    "df.dropna(subset=['noticia'])\n",
    "\n",
    "# Pré-processamento dos dados\n",
    "stop_words = set(stopwords.words('portuguese'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # remover acentuação\n",
    "    text = unidecode(text)\n",
    "    # Remover pontuações\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Tokenização\n",
    "    words = word_tokenize(text.lower())\n",
    "    # Remover stopwords\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['noticia'] = df['noticia'].apply(preprocess_text)\n",
    "\n",
    "df_treino = df[:119]\n",
    "df_validacao = df[119:]\n",
    "\n",
    "\n",
    "# Criar modelo de classificação\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_treino['noticia'], df_treino['choices'], test_size=0.3)\n",
    "\n",
    "# Definir pipeline com CountVectorizer e MultinomialNB\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', None)\n",
    "])\n",
    "\n",
    "# Definir grade de parâmetros a serem testados\n",
    "parameters = {'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "              'classifier': [MultinomialNB(), DecisionTreeClassifier()],\n",
    "              }\n",
    "\n",
    "# Criar objeto GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, scoring='accuracy')\n",
    "\n",
    "# Treinar modelos em diferentes combinações de hiperparâmetros\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Selecionar o melhor modelo com base na pontuação de validação cruzada\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_probs = best_model.predict_proba(X_test)\n",
    "\n",
    "## avalia o modelo, gerando report, matriz de confusão e acurácia\n",
    "print(best_model.score(X_test, y_test))\n",
    "\n",
    "## printa o nome do melhor modelo escolhido pelo gridsearch\n",
    "print(best_model.named_steps['classifier'])\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "## salva o modelo\n",
    "\n",
    "import pickle\n",
    "pickle.dump(best_model, open('modelo.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Desclassificar', 'Negativa', 'Neutra', 'Positiva', 'predict_final'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## treina no conjunto de validação\n",
    "\n",
    "model = pickle.load(open('modelo.pkl', 'rb'))\n",
    "\n",
    "df_validacao = df_validacao.dropna(subset=['noticia']).reset_index(drop=True)\n",
    "y_pred = model.predict_proba(df_validacao['noticia'])\n",
    "\n",
    "## eliminar o e+01 do valor numerico em pandas\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "df_predict = pd.DataFrame(y_pred, columns=clf.classes_)\n",
    "df_predict['predict_final'] = df_predict.idxmax(axis=1)\n",
    "print(df_predict.columns)\n",
    "\n",
    "df_pred_concatenado = pd.concat([df_validacao, df_predict], axis=1)\n",
    "df_pred_concatenado[['id', 'data', 'titulo', 'noticia', 'choices', 'predict_final', 'Desclassificar', 'Negativa', 'Positiva']].to_excel('validacao.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdgd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
